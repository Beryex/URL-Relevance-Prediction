{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Import Package \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\" Global variables \"\"\"\n",
    "DATA = \"./data\"\n",
    "TRAIN_DATA_PATH = f\"{DATA}/training.csv\"\n",
    "TEST_DATA_PATH = f\"{DATA}/test.csv\"\n",
    "OUTPUT_PREDICTION = f\"{DATA}/traditional_method_predictions.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to find the relationthips among the features in the dataset in order to help us decide how to utilize the combination of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load dataset \"\"\"\n",
    "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test_data = pd.read_csv(TEST_DATA_PATH)\n",
    "\n",
    "features = ['query_length', 'is_homepage', 'sig1', 'sig2', \n",
    "            'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8']\n",
    "train_features = train_data[features]\n",
    "train_labels = train_data['relevance']\n",
    "test_features = test_data[features]\n",
    "\n",
    "print(f\"We have {train_features.shape[1]} features\")\n",
    "print(f\"We have {train_features.shape[0]} total samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Standardize both dataset \"\"\"\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Remove the outlier inside dataset \"\"\"\n",
    "features_df = pd.DataFrame(train_features)\n",
    "Q1 = features_df.quantile(0.25)\n",
    "Q3 = features_df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "original_sample_num = train_features.shape[0]\n",
    "\n",
    "outlier_mask = (features_df < lower_bound) | (features_df > upper_bound)\n",
    "outlier_count = outlier_mask.sum(axis=1)\n",
    "outlier_threshold = train_features.shape[1] // 2\n",
    "mask = outlier_count <= outlier_threshold\n",
    "\n",
    "train_features = train_features[mask.values]\n",
    "train_labels = train_labels[mask.values]\n",
    "washed_sample_num = train_features.shape[0]\n",
    "print(f\"We remove {original_sample_num - washed_sample_num} outliers from dataset\")\n",
    "print(f\"Currently we have {washed_sample_num} total samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Visualize the relationships among features \"\"\"\n",
    "sns.pairplot(train_data[features])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Apply forward stepwise feature selection \"\"\"\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "all_features = ['query_length', 'is_homepage', 'sig1', 'sig2', \n",
    "                'sig3', 'sig4', 'sig5', 'sig6', 'sig7', 'sig8']\n",
    "optimal_features = []\n",
    "optimal_cur_features = []\n",
    "optimal_pre_features = []\n",
    "best_acc = 0\n",
    "for idx in range(len(all_features)):\n",
    "    best_cur_acc = 0\n",
    "    for new_feature in all_features:\n",
    "        cur_features = optimal_pre_features[:]\n",
    "        if new_feature not in optimal_pre_features:\n",
    "            cur_features.append(new_feature)\n",
    "        else:\n",
    "            continue\n",
    "        random.seed(1)\n",
    "        np.random.seed(1)\n",
    "        train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "\n",
    "        cur_train_features = train_data[cur_features]\n",
    "        cur_train_labels = train_data['relevance']\n",
    "        \n",
    "        spline_transformer = SplineTransformer(n_knots=100, degree=3)\n",
    "        model = LogisticRegression(random_state=1)\n",
    "        pipeline = make_pipeline(spline_transformer, model)\n",
    "\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "        cv_scores = cross_val_score(pipeline, cur_train_features, cur_train_labels, \n",
    "                                    cv=kf, scoring='accuracy')\n",
    "        \n",
    "        if best_cur_acc <= np.mean(cv_scores):\n",
    "            optimal_cur_features = cur_features\n",
    "            best_cur_acc = np.mean(cv_scores)\n",
    "    optimal_pre_features = optimal_cur_features\n",
    "    if best_acc <= best_cur_acc:\n",
    "        optimal_features = optimal_cur_features\n",
    "        best_acc = best_cur_acc\n",
    "print(f\"Optimal features combination: {optimal_features} with best acc: {best_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We learn that sig5 is not in the optimal features and we decide to remove it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Remove sig5 from the dataset \"\"\"\n",
    "train_features = np.concatenate((train_features[:, 0:6], train_features[:, 7:]), axis=1)\n",
    "test_features = np.concatenate((test_features[:, 0:6], test_features[:, 7:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Apply kernel method to increase features \"\"\"\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "train_features = poly.fit_transform(train_features)\n",
    "test_features = poly.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Apply PCA to remove unnecessary features \"\"\"\n",
    "pca = PCA()\n",
    "pca.fit(train_features)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio, marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "plt.title('Cumulative Explained Variance Ratio by PCA')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "n_components = np.argmax(cumulative_variance_ratio >= 0.999) + 1\n",
    "print(f\"Number of principal components to retain (99% variance): {n_components}\")\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "train_features = pca.fit_transform(train_features)\n",
    "test_features = pca.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Modeling using logistic regression  \"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "model = LogisticRegression(\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l2'], \n",
    "        'C': [0.01, 0.1, 1, 10, 100], \n",
    "        'solver': ['newton-cg', 'lbfgs', 'sag'], \n",
    "        'max_iter': [100, 300, 500]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l1'], \n",
    "        'C': [0.01, 0.1, 1, 10, 100], \n",
    "        'solver': ['liblinear'], \n",
    "        'max_iter': [100, 300, 500]\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'], \n",
    "        'C': [0.01, 0.1, 1, 10, 100], \n",
    "        'solver': ['saga'], \n",
    "        'l1_ratio': [0.2, 0.5, 0.8],  # Adding l1_ratio for elasticnet\n",
    "        'max_iter': [100, 300, 500]\n",
    "    },\n",
    "    {\n",
    "        'penalty': [None], \n",
    "        'solver': ['newton-cg', 'lbfgs', 'sag', 'saga'], \n",
    "        'max_iter': [100, 300, 500]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=1), \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Modeling using RandomForest Classifier  \"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    random_state=1,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 300],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 4],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt'],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=1), \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Modeling using Light Gradient Boosting  \"\"\"\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "model = lgb.LGBMClassifier(\n",
    "    random_state=1,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'max_depth': [-1],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'min_child_samples': [10, 20],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=1), \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy: \", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Predict on test dataset using the best model \"\"\"\n",
    "results = []\n",
    "predictions = best_model.predict(test_features)\n",
    "for idx, prediction in enumerate(predictions):\n",
    "    sample_id = str(int(test_data.iloc[idx]['query_id'])) + str(int(test_data.iloc[idx]['url_id']))\n",
    "    results.append({'id': sample_id, 'relevance': int(prediction)})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(OUTPUT_PREDICTION, index=False)\n",
    "print(f\"Predictions saved at {OUTPUT_PREDICTION}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
